{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acc85a55",
   "metadata": {},
   "source": [
    "## W3&W4 post studio exercises (errors, model fitting)\n",
    "\n",
    "Enter your solution in the cell(s) below each exercise. Add couple of inline comments explaining your code. Don't forget to add comments in markdown cell after each exercise. Missing comments (in markdown cells and/or inline) and late submissions will incur penalties.\n",
    "\n",
    "Once done, drag&drop your python file to your ADS1002-name github account.\n",
    "\n",
    "Copy url of this file on github to appropriate folder on Moodle by 09.30am prior your next studio. \n",
    "\n",
    "Solutions will be released later in the semester.\n",
    "\n",
    "Max 10 marks - 2.5 marks per each exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6239fd43",
   "metadata": {},
   "source": [
    "***\n",
    "We will use \n",
    "\n",
    "* [who-health-data.csv](https://gitlab.erc.monash.edu.au/bads/data-challenges-resources/-/tree/main/Machine-Learning/Supervised-Methods/who-health-data.csv)\n",
    "\n",
    "* [wisconsin-cancer-data.csv](https://gitlab.erc.monash.edu.au/bads/data-challenges-resources/-/tree/main/Machine-Learning/Supervised-Methods/kaggle-wisconsin-cancer.csv)\n",
    "\n",
    "throughout the exercises. Download the datasets into the same directory as your post-studio notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65429758-40aa-4c24-9a61-5291ae628683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember these? Our usual package imports for handling data.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Specialised functions for calculating prediction error rates.\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d36b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "who_data_2015 = (\n",
    "    pd.read_csv(\"who-health-data.csv\") # Read in the csv data.\n",
    "    .rename(columns=lambda c: c.strip())      # Clean up column names.\n",
    "    .query(\"Year == 2015\")                    # Restrict the dataset to records from 2015.\n",
    "    # Removes two columns which contain a lot of missing data...\n",
    "    .drop(columns=[\"Alcohol\", \"Total expenditure\"])\n",
    "    # ... then drop any rows with missing values.\n",
    "    .dropna()\n",
    ")\n",
    "\n",
    "wisconsin_cancer_biopsies = (\n",
    "    pd.read_csv(\"kaggle-wisconsin-cancer.csv\")\n",
    "    # This tidies up the naming of results (M -> malignant, B -> benign)\n",
    "    .assign(diagnosis=lambda df: df['diagnosis']  \n",
    "        .map({\"M\": \"malignant\", \"B\": \"benign\"})\n",
    "        .astype('category')\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e823bd",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Given the dataframe `ex1_who_with_predictions` below, compute the Mean Absolute Error for the predicted values of life expectancy. You can repeat the process previously shown, or find a function in `sklearn.metrics` to compute this for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce618f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex1_who_with_predictions = (\n",
    "    who_data_2015[[\"Schooling\", \"Life expectancy\"]]\n",
    "    .assign(Predicted=lambda df: df[\"Schooling\"] * 2.3 + 43)\n",
    "    .dropna()\n",
    ")\n",
    "ex1_who_with_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe70fceb-3958-43c8-88c3-a0a3e31f39bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating the Mean Absolute Error for the predicted values of life expectancy\n",
    "\n",
    "errors = ex1_who_with_predictions['Life expectancy'] - ex1_who_with_predictions['Predicted']\n",
    "mae_score = errors.abs().mean()\n",
    "print(f\"Mean absolute error is {mae_score:.1f} years\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d380e650",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Given the classification predictions and actual results in the dataframe `ex2_biopsies_with_predictions` below, compute accuracy, precision and recall. Also find the number of false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0d649c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "ex2_biopsies_with_predictions = (\n",
    "    wisconsin_cancer_biopsies\n",
    "    .assign(prediction=lambda df: df['texture_mean'].lt(20)\n",
    "        .map({True: \"benign\", False: \"malignant\"})\n",
    "    )\n",
    "    [['radius_mean', 'texture_mean', 'diagnosis', 'prediction']]\n",
    ")\n",
    "ex2_biopsies_with_predictions\n",
    "\n",
    "\n",
    "\n",
    "threshold = 20\n",
    "\n",
    "# Classify predictions based on the threshold\n",
    "ex2_biopsies_with_predictions['classified_prediction'] = ex2_biopsies_with_predictions['texture_mean'].apply(lambda x: 'malignant' if x > threshold else 'benign')\n",
    "\n",
    "# Define True Positives, True Negatives, False Positives, and False Negatives\n",
    "TP = ex2_biopsies_with_predictions[(ex2_biopsies_with_predictions['classified_prediction'] == 'malignant') & (ex2_biopsies_with_predictions['diagnosis'] == 'malignant')].shape[0]\n",
    "TN = ex2_biopsies_with_predictions[(ex2_biopsies_with_predictions['classified_prediction'] == 'benign') & (ex2_biopsies_with_predictions['diagnosis'] == 'benign')].shape[0]\n",
    "FP = ex2_biopsies_with_predictions[(ex2_biopsies_with_predictions['classified_prediction'] == 'malignant') & (ex2_biopsies_with_predictions['diagnosis'] == 'benign')].shape[0]\n",
    "FN = ex2_biopsies_with_predictions[(ex2_biopsies_with_predictions['classified_prediction'] == 'benign') & (ex2_biopsies_with_predictions['diagnosis'] == 'malignant')].shape[0]\n",
    "\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94b4c1d-f9e8-4f85-87fc-49e2b36fa6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL = TP + TN + FP + FN\n",
    "\n",
    "print(f\"Accuracy = {(TP + TN) / TOTAL = :.3f}\")\n",
    "print(f\"Precision = {TP / (TP + FP) = :.3f}\")\n",
    "print(f\"Recall = {TP / (TP + FN) = :.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2442f1dc",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Consider three different predictors for the cancer biopsy screening dataset:\n",
    "\n",
    "* Predictor A has an accuracy of 0.95, and recall of 0.99\n",
    "* Predictor B has an accuracy of 0.99, and recall of 0.95\n",
    "* Predictor C has an accuracy of 0.5, and a recall of 1.0\n",
    "\n",
    "The test required to collect data from a new patient (on which the predictor will give a predicted diagnosis) is minimally invasive. If the predictor predicts a positive (malignant) diagnosis, the patient will be referred for further screening which can be expensive.\n",
    "\n",
    "Considering the context, which predictive model (A, B, or C) would likely be preferred for this task? Write your answer in a markdown cell below, and give a brief explanation of your reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c2d75-5860-4441-be10-a9764a958e0e",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------\n",
    "<mark> Predictor B </mark>\n",
    "\n",
    "In this scenario, where the test to collect data is minimally invasive but further screening for a positive diagnosis is expensive, the choice of the predictive model involves balancing accuracy and recall.\n",
    "\n",
    "Predictor B** has the highest accuracy (0.99) and a slightly lower recall (0.95). It performs very well overall and balances between detecting positives and avoiding false positives.\n",
    "\n",
    "\n",
    "-------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54311d40",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Choose one different input/feature variable (other than Schooling) and fit a linear regression model to predict Life Expectancy using sklearn. Can you achieve a better error rate than what we found in pre-studio notebook? (RMSE and MAE for Schooling were 4.71 and 3.69, respectively.) Suggest a method to narrow down your choices of variables to use in order to arrive at a good model. \n",
    "\n",
    "Hint 1: Correlation.\n",
    "\n",
    "Hint 2: You can use the functions written in the pre-studio notebook, e.g. prediction_root_mean_squared_error(gradient, intercept), to calculate the model error once you choose your model parameters (features)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab646c5a-5383-4413-b3e8-897303056e97",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------\n",
    "<mark>Answer</mark>\n",
    "\n",
    "\n",
    "we can choose better RMSE AND MSE by having  <mark> \"Income composition of resources\" </mark> as our y intercept  <mark>(code has been provided below to show the working)</mark>\n",
    "\n",
    "I think that gradient decent method would be better to nerrow down would be better at the data set is really large and also no direct mathematical expression given to directly computr the model parameterers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe1e44d-7995-49f9-997e-963bc330325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Using BMI instead of schoolinG\n",
    "\n",
    "sns.relplot(data=who_data_2015, x=\"Income composition of resources\", y=\"Life expectancy\");\n",
    "\n",
    "who_data_2015\n",
    "#choose better error rate that found in pre reading material.\n",
    "\n",
    "\n",
    "#uggest a method to narrow down your choices of variables to use in order to arrive at a good model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbe0d21-9a22-427c-9132-24a9681827f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "def prediction_root_mean_squared_error(gradient, intercept):\n",
    "    \"\"\" Return the prediction error associated with the value of the parameters.\n",
    "    This time around, let's use sklearn.metrics. \"\"\"\n",
    "    predictions = who_data_2015[\"Income composition of resources\"] * gradient + intercept\n",
    "    actual = who_data_2015[\"Life expectancy\"]\n",
    "    # Note that `squared=False` gives us RMSE. Then we're in the same units as MAE.\n",
    "    return mean_squared_error(y_true=actual, y_pred=predictions, squared=False)\n",
    "\n",
    "def prediction_mean_absolute_error(gradient, intercept):\n",
    "    \"\"\" Return the prediction error associated with the value of the parameters.\n",
    "    This time around, let's use sklearn.metrics. \"\"\"\n",
    "    predictions = who_data_2015[\"Income composition of resources\"] * gradient + intercept\n",
    "    actual = who_data_2015[\"Life expectancy\"]\n",
    "    return mean_absolute_error(y_true=actual, y_pred=predictions)\n",
    "\n",
    "# Compute error values for different gradient and intercepts.\n",
    "# This will be used to build the colour contour plots.\n",
    "gradient_values, intercept_values = np.meshgrid(\n",
    "    np.linspace(0.5, 5.0, 30),\n",
    "    np.linspace(30, 80, 30),\n",
    ")\n",
    "rmse_errors = np.zeros(gradient_values.shape)\n",
    "for i in range(rmse_errors.shape[0]):\n",
    "    for j in range(rmse_errors.shape[1]):\n",
    "        rmse_errors[i, j] = prediction_root_mean_squared_error(gradient_values[i, j], intercept_values[i, j])\n",
    "mae_errors = np.zeros(gradient_values.shape)\n",
    "for i in range(mae_errors.shape[0]):\n",
    "    for j in range(mae_errors.shape[1]):\n",
    "        mae_errors[i, j] = prediction_mean_absolute_error(gradient_values[i, j], intercept_values[i, j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e856ab9f-d8f9-4e5f-a9be-2176fd9e9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "# This sets initial guess values (gradient = 3, intercept = 60) for the algorithm to\n",
    "# use as a starting point. You can change these and re-run the cell to observe the\n",
    "# different paths taken by the algorithm.\n",
    "initial_guess = (3, 60)\n",
    "\n",
    "# We'll record the different model parameters tested in these lists.\n",
    "gradient_steps = [initial_guess[0]]\n",
    "intercept_steps = [initial_guess[1]]\n",
    "\n",
    "def callback(values, *args, **kwargs):\n",
    "    \"\"\" This function is called by `minimize` whenever it takes a step. This allows the\n",
    "    steps to be recorded \"\"\"\n",
    "    gradient_steps.append(values[0])\n",
    "    intercept_steps.append(values[1])\n",
    "\n",
    "def prediction_error(coefficients):\n",
    "    \"\"\" This function is called with both coefficients (gradient and intercept) as a tuple.\n",
    "    It returns the result of the error calculation which scipy.optimise will use \"\"\"\n",
    "    gradient, intercept = coefficients\n",
    "    return prediction_root_mean_squared_error(gradient, intercept)\n",
    "\n",
    "# Run the gradient descent algorithm and extract the optimal model parameter values.\n",
    "opt_result = minimize(\n",
    "    prediction_error,      # error evaluation function\n",
    "    initial_guess,         # an initial guess of the model parameters\n",
    "    callback=callback,     # a function to record trial points\n",
    ")\n",
    "\n",
    "# This gives some status information and the model parameter results.\n",
    "opt_result\n",
    "\n",
    "\n",
    "optimal_gradient, optimal_intercept = opt_result.x\n",
    "print(\"Model is y = {:.2f}x + {:.2f}\".format(optimal_gradient, optimal_intercept))\n",
    "print(\"RMSE = {:.2f}\".format(prediction_root_mean_squared_error(optimal_gradient, optimal_intercept)))\n",
    "print(\"MAE = {:.2f}\".format(prediction_mean_absolute_error(optimal_gradient, optimal_intercept)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d047d49b",
   "metadata": {},
   "source": [
    "## Extra exercises\n",
    "\n",
    "The following exercises with (*) will not be assessed. Use these to check your understanding of topics covered in the past 2 weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c7caa6",
   "metadata": {},
   "source": [
    "### Exercise 5*\n",
    "\n",
    "The function `model_correct_predictions` below returns the number of correct predictions made by a predictive model for the cancer biopsy dataset, for a given parameter value. This parameter value simply controls the threshold value for radius above which a sample is predicted as malignant.\n",
    "\n",
    "Try different values of the parameter in this model within the range [0, 30]. Record and plot the resulting accuracy values against the parameter value (similar to the regression cost function example above).\n",
    "\n",
    "What value of the parameter provides the best error rate? Explain how can you be confident you have found the best result here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd0a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_correct_predictions(radius_split_parameter):\n",
    "    \"\"\" Return the number of correct predictions made by the model\n",
    "    for the given parameter value. \"\"\"\n",
    "    data = wisconsin_cancer_biopsies.assign(\n",
    "        predicted=lambda df: df['radius_mean'].lt(radius_split_parameter)\n",
    "            .map({True: \"benign\", False: \"malignant\"})\n",
    "    )\n",
    "    return (data['diagnosis'] == data['predicted']).sum()\n",
    "\n",
    "model_correct_predictions(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5418d4af",
   "metadata": {},
   "source": [
    "### Exercise 6*\n",
    "\n",
    "In examples in pre-studio notebook (W4) we have used root mean squared error (the standard cost function for linear regression) to fit the model parameters. Try re-running the `scipy.optimise` method using mean absolute error. Are the resulting model parameters the same as above? Give some brief reasoning why there might be a difference here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dd55f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hint: you only need to make one small change in the prediction_error function to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc09b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_root_mean_squared_error(gradient, intercept):\n",
    "    \"\"\" Return the prediction error associated with the value of the parameters.\n",
    "    This time around, let's use sklearn.metrics. \"\"\"\n",
    "    predictions = who_data_2015[\"Schooling\"] * gradient + intercept\n",
    "    actual = who_data_2015[\"Life expectancy\"]\n",
    "    # Note that `squared=False` gives us RMSE. Then we're in the same units as MAE.\n",
    "    return mean_squared_error(y_true=actual, y_pred=predictions, squared=False)\n",
    "\n",
    "def prediction_mean_absolute_error(gradient, intercept):\n",
    "    \"\"\" Return the prediction error associated with the value of the parameters.\n",
    "    This time around, let's use sklearn.metrics. \"\"\"\n",
    "    predictions = who_data_2015[\"Schooling\"] * gradient + intercept\n",
    "    actual = who_data_2015[\"Life expectancy\"]\n",
    "    return mean_absolute_error(y_true=actual, y_pred=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bd1b2a",
   "metadata": {},
   "source": [
    "### Exercise 7*\n",
    "\n",
    "We can see above that different methods for determining model parameters arrive at the same result, but what happens if we change the dataset slightly. Experiment by taking several (at least 10) different samples of the data, fitting a linear model for each one, and plotting a histogram of the different gradient and intercept coefficients you find. Is there a significant amount of variation in the parameter values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e345346",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = who_data_2015.sample(30)  # selects a small sample of 30 random rows from the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
